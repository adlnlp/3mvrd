{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO99E3f6m1a+fre/gdWF2u/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vuI1h6c9TRz7"},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","import pickle\n","from transformers import AutoModel,AutoTokenizer\n","from torch.utils.data import Dataset\n","import argparse\n","import json\n","import pandas as pd"]},{"cell_type":"markdown","source":["#Feature Extractor Class\n","Define e textual encoder, e.g., \"bert-base-uncased\", encode the input text and extract the CLS token as final textual representation"],"metadata":{"id":"jMORjwoqL99t"}},{"cell_type":"code","source":["class feature_extractor(torch.nn.Module):\n","    def __init__(self):\n","        super(feature_extractor, self).__init__()\n","        self.bigbird = AutoModel.from_pretrained('bert-base-uncased')\n","\n","    def forward(self, input_ids, attention_mask):\n","        input_ids = input_ids.squeeze(1)\n","        attention_mask = attention_mask.squeeze(1)\n","        outputs = self.bigbird(input_ids=input_ids,attention_mask=attention_mask)\n","        outputs = outputs[0]\n","        cls = outputs[:, 0, :]\n","        return cls"],"metadata":{"id":"P9vGjwbDKYsM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Dataset Class\n","Tokenize the input text and return corresponding *input_ids* and *attention_mask*"],"metadata":{"id":"ONu1FRxYMRlY"}},{"cell_type":"code","source":["class data_prepare(Dataset):\n","    def __init__(self, sentences, tokenizer):\n","        self.text = sentences\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        text = self.text[index]\n","        encoded_dict = tokenizer(\n","            text,\n","            max_length=512,  # Pad & truncate all sentences\n","            pad_to_max_length=True,\n","            return_tensors='pt',  # Return pytorch tensors\n","        )\n","        return {\n","            'ids': torch.tensor(encoded_dict['input_ids'], dtype=torch.long),\n","            'mask': torch.tensor(encoded_dict['attention_mask'], dtype=torch.long)\n","        }"],"metadata":{"id":"kr7ni0wQK_pA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Main\n"],"metadata":{"id":"02yO9sOeMdgI"}},{"cell_type":"code","source":["parser = argparse.ArgumentParser()\n","parser.add_argument(\"--split\", type=str, default=\"train\", choices=[\"train\", \"test\"])\n","args = parser.parse_args()\n","split = args.split"],"metadata":{"id":"AdWNM_xiLQXT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Read entity annotated FUNSD data. They can be downloaded from: https://guillaumejaume.github.io/FUNSD/download/"],"metadata":{"id":"iJ6vrw1TMfwJ"}},{"cell_type":"code","source":["with open(\"data/FUNSD/dataset/\"+split+\"ing_data/all_annotations.json\", 'r') as f:\n","    data = json.load(f)\n","    sentences = []\n","    boxes = []\n","    for key in data.keys():\n","        doc = data[key][\"form\"]\n","        for i in range(len(doc)):\n","            sentences.append(doc[i][\"text\"])\n","            boxes.append(doc[i][\"box\"])"],"metadata":{"id":"qt7-sLleLaD2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Apply feature extractor"],"metadata":{"id":"fFBe7UIeNCfV"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n","model = feature_extractor()\n","model.to(device)\n","model.eval()\n","data = data_prepare(sentences, tokenizer)\n","loader = torch.utils.data.DataLoader(data, batch_size=32, shuffle=False)\n","\n","\n","features = []\n","for batch in tqdm(loader):\n","    input_ids = batch['ids'].to(device)\n","    attention_mask = batch['mask'].to(device)\n","    with torch.no_grad():\n","        feature = model(input_ids, attention_mask)\n","    features.append(feature)\n","\n","features = torch.cat(features, dim=0)\n","features = features.cpu().numpy()"],"metadata":{"id":"dlJzKb8pK9sX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Create a pandas datafram containing the computed textual features"],"metadata":{"id":"9gOgPwFzLunW"}},{"cell_type":"code","source":["df = pd.DataFrame()\n","df[\"id\"] = list(range(len(sentences)))\n","df[\"text\"] = sentences\n","df[\"boxes\"] = boxes\n","df[\"features\"] = features.tolist()"],"metadata":{"id":"l8s3FVBtLgf6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Save features as Pickle file"],"metadata":{"id":"1FhUmhs2Ll5L"}},{"cell_type":"code","source":["with open(\"data/FUNSD/dataset/\"+split+\"ing_data/textual_features.pickle\", 'wb') as f:\n","    pickle.dump(df, f)"],"metadata":{"id":"KP9rHAOFLiaj"},"execution_count":null,"outputs":[]}]}