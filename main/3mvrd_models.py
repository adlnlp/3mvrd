# -*- coding: utf-8 -*-
"""3mvrd_models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/190m3YqWk2AmwMq8x4TvqD0kbPnuU6JEL
"""

class visualbert(torch.nn.Module):
    def __init__(self):
        super(visualbert, self).__init__()
        self.l1 = VisualBertModel.from_pretrained("uclanlp/visualbert-vqa-coco-pre",output_hidden_states=True)
        self.pre_classifier = torch.nn.Linear(768, 768)
        self.dropout = torch.nn.Dropout(0.1)
        self.classifier = torch.nn.Linear(768, 7)

    def forward(self, ids, mask, token_type_ids, visual_feat, attention_mask):
        visual_token_type_ids = torch.ones(visual_feat.shape[:-1], dtype=torch.long).to(device, dtype = torch.long)
        visual_attention_mask = attention_mask.to(device, dtype = torch.float)
        output_1 = self.l1(input_ids=ids, attention_mask=mask, token_type_ids=token_type_ids,
                                        visual_embeds=visual_feat, visual_token_type_ids=visual_token_type_ids,visual_attention_mask=visual_attention_mask)
        hidden_state = output_1.hidden_states[-1]
        visual_feat = hidden_state[:, 512:,:]
        pre_cls_state = self.pre_classifier(visual_feat)
        output = torch.nn.Tanh()(pre_cls_state)
        output = self.dropout(output)
        output = self.classifier(output)
        return visual_feat, pre_cls_state, output

class lxmert(torch.nn.Module):
    def __init__(self):
        super(lxmert, self).__init__()
        self.l1 = LxmertModel.from_pretrained("unc-nlp/lxmert-base-uncased",output_hidden_states = True)
        self.pre_classifier = torch.nn.Linear(768, 768)
        self.dropout = torch.nn.Dropout(0.1)
        self.classifier = torch.nn.Linear(768, 7)

    def forward(self, ids, mask, token_type_ids, visual_feat,attention_mask,norm_bbox):
        visual_attention_mask = attention_mask.to(device, dtype = torch.float)
        output_1 = self.l1(input_ids=ids,
                           attention_mask=mask,
                           token_type_ids=token_type_ids,
                           visual_feats =visual_feat,
                           visual_pos = norm_bbox,
                           visual_attention_mask=visual_attention_mask)
        #question = output_1.language_hidden_states[-1]
        visual_feat = output_1.vision_hidden_states[-1]
        pre_cls_state = self.pre_classifier(visual_feat)
        output = torch.nn.Tanh()(pre_cls_state)
        output = self.dropout(output)
        output = self.classifier(output)
        return visual_feat, pre_cls_state, output

class lilt(torch.nn.Module):
    def __init__(self):
        super(lilt, self).__init__()


        self.lilt = AutoModel.from_pretrained("SCUT-DLVCLab/lilt-roberta-en-base",output_hidden_states=True)
        self.dropout = torch.nn.Dropout(0.1)
        self.classifier = torch.nn.Linear(768, 15)

    def forward(self, input_ids, attention_mask, token_type_ids, bbox):
        input_ids = input_ids.squeeze()
        attention_mask = attention_mask.squeeze()
        token_type_ids = token_type_ids.squeeze()
        bbox = bbox.squeeze()
        outputs = self.lilt(input_ids=input_ids, attention_mask=attention_mask, token_type_ids = token_type_ids ,bbox = bbox)

        sequence_output = outputs[0]
        sequence_output = self.dropout(sequence_output)
        logits = self.classifier(sequence_output)
        return{
            'logits':logits,
            'hidden_states':outputs.hidden_states
            }

class layoutlmv3(torch.nn.Module):
    def __init__(self):
        super(layoutlmv3, self).__init__()


        self.layoutlmv3 = AutoModel.from_pretrained("microsoft/layoutlmv3-base",output_hidden_states=True)
        self.dropout = torch.nn.Dropout(0.1)
        self.classifier = torch.nn.Linear(768, 15)

    def forward(self, input_ids, attention_mask, pixel_values, bbox):
        input_ids = input_ids.view(-1, input_ids.size(-1))
        attention_mask = attention_mask.view(-1, attention_mask.size(-1))
        pixel_values = pixel_values.squeeze()
        bbox = bbox.squeeze()

        outputs = self.layoutlmv3(input_ids=input_ids, attention_mask=attention_mask, pixel_values = pixel_values ,bbox = bbox)

        seq_length = input_ids.size()[1]
        # only take the text part of the output representations
        sequence_output = outputs[0][:, :seq_length]
        sequence_output = self.dropout(sequence_output)
        logits = self.classifier(sequence_output)
        return{
            'logits':logits,
            'hidden_states':outputs.hidden_states
            }

class mmm_framework(torch.nn.Module):
    def __init__(self):
        super(mmm_framework, self).__init__()
        # Teacher models
        self.lxmert = lxmert
        self.visualbert = visualbert
        self.layoutlmv3 = layoutlmv3
        self.lilt = lilt

        # Define Student Model
        self.encoder_layer1 = torch.nn.TransformerEncoderLayer(d_model=768, nhead=8)
        self.transformer_encoder = torch.nn.TransformerEncoder(self.encoder_layer1, num_layers=6) # recommened to 2

        self.token_decoder_layer = torch.nn.TransformerDecoderLayer(d_model=768, nhead=8,batch_first=True)
        self.token_transformer_decoder = torch.nn.TransformerDecoder(self.token_decoder_layer, num_layers=2)

        self.entity_decoder_layer = torch.nn.TransformerDecoderLayer(d_model=768, nhead=8,batch_first=True)
        self.entity_transformer_decoder = torch.nn.TransformerDecoder(self.entity_decoder_layer, num_layers=2)

        self.token_projector = torch.nn.Linear(768*2, 768)
        self.entity_projector = torch.nn.Linear(768*2, 768)
        self.lxmert_projector = torch.nn.Linear(768*2, 768)
        self.visualbert_projector = torch.nn.Linear(768*2, 768)

        self.linear_objects = torch.nn.Linear(768*3, 768)
        self.entity_pre_classifier = torch.nn.Linear(768, 768)
        self.dropout = torch.nn.Dropout(0.1)
        self.entity_classifier = torch.nn.Linear(768, 7)

        self.token_pre_classifier = torch.nn.Linear(768, 768)
        self.dropout = torch.nn.Dropout(0.1)
        self.token_classifier = torch.nn.Linear(768, 15)


    def forward(self, visualbert_ids, visualbert_mask, visualbert_token_type_ids,lxmert_ids, lxmert_mask, lxmert_token_type_ids,
                input_ids, bbox, pixel_values, token_attention_mask, token_type_ids,
                visual_feat, bert_cls, entity_attention_mask, norm_bbox, positional_encoding):

        # *****************************Teacher Encoder*****************************

        # ------------------------Token level -----------------------------
        ## Get Layoutlmv3 (lm) logits and hiddenstates (hs)
        input_ids = input_ids.view(-1, input_ids.size(-1))
        token_attention_mask = token_attention_mask.view(-1, token_attention_mask.size(-1))



        pixel_values = pixel_values.squeeze(1)
        bbox = bbox.squeeze(1)
        layoutlmv3_outputs = self.layoutlmv3(input_ids=input_ids, attention_mask=token_attention_mask, pixel_values = pixel_values ,bbox = bbox)
        lm_logits = layoutlmv3_outputs['logits']
        lm_hs = layoutlmv3_outputs['hidden_states'][-1][:, :512,:]
        #print(layoutlmv3_outputs.keys())
        ## Get LiLT (ll) logits and hiddenstates (hs)
        input_ids = input_ids.squeeze(1)
        attention_mask = token_attention_mask.squeeze(1)
        token_type_ids = token_type_ids.squeeze(1)
        bbox = bbox.squeeze(1)

        lilt_outputs = self.lilt(input_ids=input_ids, attention_mask=attention_mask, token_type_ids = token_type_ids ,bbox = bbox)
        ll_logits = lilt_outputs['logits']
        #print('ll_logits:',ll_logits.shape)
        ll_hs = lilt_outputs['hidden_states'][-1]
        # ------------------------Entity level ----------------------------

        ## Get lxmert logits and hiddenstates (hs)
        #def forward(self, ids, mask, token_type_ids, visual_feat,attention_mask,norm_bbox):
        lx_visual_feat, lx_pre_cls_state, lx_logits = self.lxmert(ids=lxmert_ids,mask=lxmert_mask,
                      token_type_ids=lxmert_token_type_ids,visual_feat =visual_feat,
                      norm_bbox = norm_bbox,attention_mask=entity_attention_mask)

        ## Get visualbert logits and hiddenstates (hs)
        vb_visual_feat, vb_pre_cls_state, vb_logits= self.visualbert(ids=visualbert_ids, mask=visualbert_mask, token_type_ids=visualbert_token_type_ids,
                                        visual_feat=visual_feat,attention_mask = entity_attention_mask)

        # ***********************Token/Entity Representations*********************
        token_feats = torch.cat((ll_hs,lm_hs),2)
        token_feats = self.token_projector(token_feats)

        lx_objects = torch.cat((lx_visual_feat,bert_cls),2)
        lx_objects = self.lxmert_projector(lx_objects)

        vb_objects = torch.cat((vb_visual_feat,bert_cls),2)
        vb_objects = self.visualbert_projector(vb_objects)

        entity_feats = torch.cat((vb_objects,lx_objects),2)
        entity_feats = self.entity_projector(entity_feats)

        # *****************************Student Decoder****************************
        encoder_mask = torch.cat((attention_mask,entity_attention_mask),1)
        encoder_mask = torch.transpose(encoder_mask,0,1)
        encoder_mask = 1-encoder_mask
        inputs = torch.cat((token_feats,entity_feats),1)
        inputs += positional_encoding

        encoder_output = self.transformer_encoder(inputs,src_key_padding_mask=encoder_mask)

        token_feats = encoder_output[:,:512,:]
        entity_feats = encoder_output[:,512:,:]
        # *****************************Student Decoder****************************
        entity_attention_padding_mask = 1-entity_attention_mask
        token_attention_padding_mask = 1-attention_mask
        entity_feats_decoder = self.entity_transformer_decoder(entity_feats,token_feats,tgt_key_padding_mask=entity_attention_padding_mask,memory_key_padding_mask=token_attention_padding_mask)

        token_feats_decoder = self.token_transformer_decoder(token_feats,entity_feats,tgt_key_padding_mask=token_attention_padding_mask,memory_key_padding_mask=entity_attention_padding_mask)

        # Student Entity Representation
        entity_final_feats = self.entity_pre_classifier(entity_feats_decoder)
        entity_final_feats = torch.nn.Tanh()(entity_final_feats)
        entity_final_feats = self.dropout(entity_final_feats)
        std_entity_logits = self.entity_classifier(entity_final_feats)

        # Student Token Representation
        token_final_feats = self.token_pre_classifier(token_feats_decoder)
        token_final_feats = torch.nn.Tanh()(token_final_feats)
        token_final_feats = self.dropout(token_final_feats)
        std_token_logits = self.token_classifier(token_final_feats)
        # *****************************Warm Traning****************************

        token_entity_logits = torch.bmm(token_feats, entity_feats.permute(0, 2, 1))
        #print(token_entity_logits.shape)
        return{
            "entity_t1_hidden": lx_visual_feat,
            "entity_t2_hidden": vb_visual_feat,
            "entity_t1_logits": lx_logits,
            "entity_t2_logits": vb_logits,
            "token_t1_hidden": lm_hs,
            "token_t2_hidden": ll_hs,
            "token_t1_logits": lm_logits,
            "token_t2_logits": ll_logits,
            "std_token_logits": std_token_logits,
            "std_entity_logits": std_entity_logits,
            "std_token_hidden": token_feats,
            "std_entity_hidden": entity_feats,
            "token_entity_logits": token_entity_logits
        }