# -*- coding: utf-8 -*-
"""Untitled71.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jrOPKUFoOfQfkTmZ9IvbDtxH1X2KOX6r
"""

def eval(test_dataloader):
    preds_entity = None
    out_entity_label_ids = None
    preds_token = None
    out_token_label_ids = None
    model.eval()
    total_loss = 0
    for data in tqdm(test_dataloader):
        with torch.no_grad():
            # get the inputs;
            token_inputs = data['token_encoding']
            input_ids = token_inputs['input_ids'].to(device, dtype = torch.long)
            bbox = token_inputs['bbox'].to(device, dtype = torch.long)
            pixel_values = token_inputs['pixel_values'].to(device, dtype = torch.float)
            token_labels = token_inputs['labels'].to(device, dtype = torch.long)
            token_attention_mask = token_inputs['attention_mask'].to(device, dtype = torch.float)
            token_type_ids = token_inputs['token_type_ids'].to(device, dtype = torch.long)
            objt_ids = data['objt_ids'].to(device, dtype = torch.long)

            # get the visualbert inputs
            visualbert_ids = data['visualbert_ids'].to(device, dtype = torch.long)
            visualbert_mask = data['visualbert_mask'].to(device, dtype = torch.float)
            visualbert_token_type_ids = data['visualbert_token_type_ids'].to(device, dtype = torch.long)

            # get the lxmert inputs
            lxmert_ids = data['lxmert_ids'].to(device, dtype = torch.long)
            lxmert_mask = data['lxmert_mask'].to(device, dtype = torch.float)
            lxmert_token_type_ids = data['lxmert_token_type_ids'].to(device, dtype = torch.long)

            # entity representations
            entity_labels = data['target'].to(device, dtype = torch.long)
            visual_feats = data['visual_feat'].to(device, dtype = torch.float)
            bert_cls = data['bert_cls'].to(device, dtype = torch.float)
            entity_attention_mask = data['object_mask'].to(device, dtype = torch.float)
            norm_bbox = data['norm_bbox'].to(device, dtype = torch.float)
            positional_encoding = data['positional_encoding'].to(device, dtype = torch.float)


            optimizer.zero_grad()
            output_dict = model(visualbert_ids, visualbert_mask, visualbert_token_type_ids,
                lxmert_ids, lxmert_mask, lxmert_token_type_ids,
                input_ids, bbox, pixel_values, token_attention_mask,token_type_ids,
                visual_feats,bert_cls,entity_attention_mask,norm_bbox,positional_encoding)

            # Entity Output
            entity_logits = output_dict['std_entity_logits']

            if preds_entity is None:
                preds_entity = entity_logits.detach().cpu().numpy()
                out_entity_label_ids = data["target"].detach().cpu().numpy()
            else:
                preds_entity = np.append(preds_entity, entity_logits.detach().cpu().numpy(), axis=0)
                out_entity_label_ids = np.append(out_entity_label_ids, data["target"].detach().cpu().numpy(), axis=0)
            # Token Output
            token_logits = output_dict['std_token_logits']

            if preds_token is None:
                preds_token = token_logits.detach().cpu().numpy()
                out_token_label_ids = token_inputs["labels"].detach().cpu().numpy()
            else:
                preds_token = np.append(preds_token, token_logits.detach().cpu().numpy(), axis=0)
                out_token_label_ids = np.append(out_token_label_ids, token_inputs["labels"].detach().cpu().numpy(), axis=0)
    print(preds_token.shape)
    print("Val Loss:", total_loss/len(test_dataloader))
    print()
    print("---------------------------Entity Results---------------------------")
    pprint.pprint(compute_metrics_entity((preds_entity, out_entity_label_ids)))
    print("---------------------------Token Results----------------------------")
    pprint.pprint(compute_metrics_token((preds_token, out_token_label_ids)))

    return compute_metrics_entity((preds_entity, out_entity_label_ids)),compute_metrics_token((preds_token, out_token_label_ids))